{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11384364,"sourceType":"datasetVersion","datasetId":7128467}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# RAG-Based Health Misinformation Detection for COVID-19 Tweets\n# Complete implementation for Kaggle environment with fixed API and training args\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport torch\nimport transformers\nfrom transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\nfrom transformers import Trainer, TrainingArguments\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nimport requests\nimport time\nfrom datasets import Dataset\nfrom tqdm.auto import tqdm\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint(f\"Using transformers version: {transformers.__version__}\")\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\n\n# Set random seeds for reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# ------------------------------------------\n# 1. Load and Preprocess the Dataset\n# ------------------------------------------\n\ndf = pd.read_csv('/kaggle/input/merged-covid-misinformation/merged_dataset.csv')  # Adjust path if needed\nprint(f\"Loaded dataset with {len(df)} entries\")\nprint(df.head())\n\n# Check class distribution\nprint(\"\\nClass distribution:\")\nprint(df['label'].value_counts())\n\n# Convert labels to binary format\ndf['label_encoded'] = df['label'].apply(lambda x: 1 if x == 'misinformation' else 0)\n\n# Basic preprocessing\ndef preprocess_tweet(text):\n    \"\"\"Basic preprocessing for tweets\"\"\"\n    if isinstance(text, str):\n        # Convert to lowercase\n        text = text.lower()\n        # Remove URLs (simple regex)\n        text = ' '.join([word for word in text.split() if not word.startswith('http')])\n        # Remove multiple spaces\n        text = ' '.join(text.split())\n        return text\n    return \"\"\n\ndf['processed_text'] = df['content'].apply(preprocess_tweet)\n\n# ------------------------------------------\n# 2. External Knowledge Retrieval Functions\n# ------------------------------------------\n\n# For fact-checking sources (using a local database of COVID facts)\ndef retrieve_from_factcheck(query):\n    \"\"\"Retrieve from local database of COVID facts\"\"\"\n    # Common COVID facts and misconceptions\n    covid_facts = {\n        \"covid cure\": \"There is no known cure for COVID-19, but vaccines are effective in preventing severe illness.\",\n        \"covid vaccine\": \"COVID-19 vaccines have been scientifically proven to be safe and effective.\",\n        \"5g covid\": \"There is no scientific evidence linking 5G technology to COVID-19.\",\n        \"mask\": \"Masks help reduce the spread of COVID-19 by blocking respiratory droplets.\",\n        \"hydroxychloroquine\": \"Studies have not shown hydroxychloroquine to be effective against COVID-19.\",\n        \"vitamin\": \"While vitamins support immune health, no vitamin has been proven to prevent or cure COVID-19.\",\n        \"microchip\": \"COVID-19 vaccines do not contain microchips or tracking devices.\",\n        \"bill gates\": \"Claims that Bill Gates is using vaccines for population control are false.\",\n        \"covid lab\": \"The scientific consensus is that COVID-19 was not artificially created in a laboratory.\",\n        \"covid hoax\": \"COVID-19 is a real disease that has caused millions of deaths worldwide.\",\n        \"covid fake\": \"COVID-19 is a real disease, not a hoax or conspiracy.\",\n        \"lockdown\": \"Lockdowns were implemented to slow the spread of COVID-19 and prevent healthcare systems from being overwhelmed.\",\n        \"pcr test\": \"PCR tests are reliable for detecting the presence of the SARS-CoV-2 virus that causes COVID-19.\",\n        \"covid deaths\": \"COVID-19 has caused millions of deaths globally, as confirmed by excess mortality studies.\",\n        \"covid origin\": \"Scientific evidence suggests COVID-19 originated from animal-to-human transmission.\",\n        \"covid symptoms\": \"Common COVID-19 symptoms include fever, cough, fatigue, and loss of taste or smell.\",\n        \"quarantine\": \"Quarantine helps prevent the spread of COVID-19 by isolating potentially infected individuals.\",\n        \"covid test\": \"COVID-19 tests are designed to detect current or past infection with the SARS-CoV-2 virus.\",\n        \"covid treatment\": \"COVID-19 treatments may include antivirals, monoclonal antibodies, or supportive care.\",\n        \"covid statistics\": \"COVID-19 case and death statistics are tracked by health organizations worldwide.\",\n        \"covid immunity\": \"Both vaccination and prior infection can provide some immunity against COVID-19.\",\n        \"covid variants\": \"COVID-19 variants emerge through genetic mutations in the SARS-CoV-2 virus.\",\n        \"vaccine side effects\": \"COVID-19 vaccines can cause temporary side effects like fatigue or soreness, but serious side effects are extremely rare.\",\n        \"ivermectin\": \"Medical authorities do not recommend ivermectin for COVID-19 treatment outside of clinical trials.\",\n        \"covid children\": \"Children can contract and transmit COVID-19, though they typically have milder symptoms than adults.\",\n        \"natural immunity\": \"Natural immunity from infection provides some protection, but vaccination is still recommended.\",\n        \"vaccine mandate\": \"Vaccine mandates have been implemented in some places to increase vaccination rates and protect public health.\",\n        \"covid restrictions\": \"COVID-19 restrictions were implemented to reduce transmission and save lives.\",\n        \"covid conspiracy\": \"Scientific evidence contradicts conspiracy theories about COVID-19's origin or purpose.\",\n        \"covid survival rate\": \"While many people survive COVID-19, it has caused millions of deaths worldwide.\",\n        \"wuhan\": \"The first identified cases of COVID-19 were in Wuhan, China in late 2019.\",\n        \"who covid\": \"The World Health Organization provides guidance on COVID-19 prevention, detection, and treatment.\",\n        \"cdc covid\": \"The CDC provides evidence-based guidance on COVID-19 for the United States.\",\n        \"covid pneumonia\": \"COVID-19 can cause pneumonia, a serious lung infection.\",\n        \"covid testing\": \"COVID-19 testing is an important tool for detecting and controlling the spread of the virus.\",\n        \"asymptomatic\": \"People with asymptomatic COVID-19 can still spread the virus to others.\",\n        \"covid vaccine safety\": \"COVID-19 vaccines have undergone rigorous safety testing and continuous monitoring.\",\n        \"covid hospitalization\": \"COVID-19 can lead to hospitalization, especially for unvaccinated individuals and those with risk factors.\",\n        \"long covid\": \"Some COVID-19 patients experience persistent symptoms, known as Long COVID.\",\n        \"false positive\": \"False positives in COVID-19 testing are possible but rare with PCR tests when performed correctly.\"\n    }\n    \n    # Check if any key phrases are in the query\n    for key, fact in covid_facts.items():\n        if key in query.lower():\n            return fact\n    \n    return \"No specific fact-check information found for this query.\"\n\n# Combined retrieval function that doesn't rely on external APIs\ndef retrieve_knowledge(tweet):\n    \"\"\"Retrieve external knowledge for a tweet using only local data\"\"\"\n    # Extract key phrases from tweet (simplified approach)\n    words = tweet.lower().split()\n    query = \" \".join([w for w in words if len(w) > 3 and w not in ['this', 'that', 'with', 'from', 'what', 'when']])\n    \n    # Add 'covid' to the query if not present and the tweet is about COVID\n    if 'covid' not in query and ('covid' in tweet.lower() or 'coronavirus' in tweet.lower()):\n        query = 'covid ' + query\n    \n    # Limit query length\n    query = ' '.join(query.split()[:7])\n    \n    # Get information from fact-check source\n    factcheck_info = retrieve_from_factcheck(query)\n    \n    if factcheck_info != \"No specific fact-check information found for this query.\":\n        return \"FACT CHECK: \" + factcheck_info\n    \n    # If no specific fact check found, provide general COVID information\n    covid_general_info = {\n        \"general\": \"COVID-19 is caused by the SARS-CoV-2 virus and spreads primarily through respiratory droplets.\",\n        \"symptoms\": \"Common COVID-19 symptoms include fever, cough, fatigue, and loss of taste or smell.\",\n        \"prevention\": \"Preventive measures for COVID-19 include vaccination, masks, physical distancing, and hand hygiene.\",\n        \"treatment\": \"COVID-19 treatment may include antivirals, monoclonal antibodies, or supportive care depending on severity.\",\n        \"vaccine\": \"COVID-19 vaccines are safe, effective, and reduce risk of severe illness and hospitalization.\"\n    }\n    \n    # Select relevant general information\n    for key, info in covid_general_info.items():\n        if key in query:\n            return \"GENERAL INFO: \" + info\n    \n    return \"GENERAL INFO: \" + covid_general_info[\"general\"]\n\n# ------------------------------------------\n# 3. Testing the Retrieval Function\n# ------------------------------------------\n\n# Let's test our retrieval function on a few examples\ntest_tweets = df['processed_text'].iloc[:5].tolist()\nprint(\"\\nTesting retrieval function on sample tweets:\")\nfor tweet in test_tweets:\n    print(\"\\nTWEET:\", tweet[:100], \"...\")\n    knowledge = retrieve_knowledge(tweet)\n    print(\"RETRIEVED:\", knowledge[:100], \"...\")\n\n# ------------------------------------------\n# 4. Retrieve Knowledge for All Tweets\n# ------------------------------------------\n\n# Determine sample size: use full dataset if small, otherwise sample\nsample_size = min(1000, len(df))\nif len(df) > sample_size:\n    print(f\"\\nUsing a sample of {sample_size} tweets to avoid computational overhead\")\n    sampled_indices = np.random.choice(len(df), size=sample_size, replace=False)\n    df_sample = df.iloc[sampled_indices].copy()\nelse:\n    df_sample = df.copy()\n\n# Retrieve knowledge for the sampled tweets\nprint(\"\\nRetrieving external knowledge for tweets...\")\ndf_sample['retrieved_knowledge'] = \"\"\nfor idx, row in tqdm(df_sample.iterrows(), total=len(df_sample)):\n    knowledge = retrieve_knowledge(row['processed_text'])\n    df_sample.at[idx, 'retrieved_knowledge'] = knowledge\n\n# Display a few examples\nprint(\"\\nExamples of retrieved knowledge:\")\nfor i in range(min(5, len(df_sample))):\n    print(\"\\nTWEET:\", df_sample['processed_text'].iloc[i][:100], \"...\")\n    print(\"RETRIEVED:\", df_sample['retrieved_knowledge'].iloc[i][:100], \"...\")\n    print(\"LABEL:\", df_sample['label'].iloc[i])\n\n# ------------------------------------------\n# 5. Prepare Data for RAG Model\n# ------------------------------------------\n\n# Split into train, validation, and test sets\ntrain_df, temp_df = train_test_split(df_sample, test_size=0.3, random_state=42, stratify=df_sample['label_encoded'])\nval_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['label_encoded'])\n\nprint(\"\\nData split sizes:\")\nprint(f\"Train: {len(train_df)}, Validation: {len(val_df)}, Test: {len(test_df)}\")\n\n# Create a new column combining tweet and retrieved knowledge\ndef combine_text_and_knowledge(text, knowledge):\n    return f\"Tweet: {text} [SEP] Knowledge: {knowledge}\"\n\ntrain_df['combined_text'] = train_df.apply(lambda x: combine_text_and_knowledge(\n    x['processed_text'], x['retrieved_knowledge']), axis=1)\nval_df['combined_text'] = val_df.apply(lambda x: combine_text_and_knowledge(\n    x['processed_text'], x['retrieved_knowledge']), axis=1)\ntest_df['combined_text'] = test_df.apply(lambda x: combine_text_and_knowledge(\n    x['processed_text'], x['retrieved_knowledge']), axis=1)\n\n# Convert to HuggingFace datasets\ntrain_dataset = Dataset.from_pandas(train_df[['combined_text', 'label_encoded']])\nval_dataset = Dataset.from_pandas(val_df[['combined_text', 'label_encoded']])\ntest_dataset = Dataset.from_pandas(test_df[['combined_text', 'label_encoded']])\n\n# ------------------------------------------\n# 6. Define Model and Tokenizer\n# ------------------------------------------\n\n# We'll use a pre-trained model well-suited for tweet classification\nmodel_name = \"distilbert-base-uncased\"  # Smaller model for faster training\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# Define maximum sequence length\nmax_length = 512  # Long enough for tweet + retrieved knowledge\n\n# Tokenization function\ndef tokenize_function(examples):\n    return tokenizer(\n        examples['combined_text'],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=max_length\n    )\n\n# Apply tokenization\ntokenized_train = train_dataset.map(tokenize_function, batched=True)\ntokenized_val = val_dataset.map(tokenize_function, batched=True)\ntokenized_test = test_dataset.map(tokenize_function, batched=True)\n\n# ------------------------------------------\n# 7. Define Performance Metrics\n# ------------------------------------------\n\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n    acc = accuracy_score(labels, preds)\n    return {\n        'accuracy': acc,\n        'f1': f1,\n        'precision': precision,\n        'recall': recall\n    }\n\n# ------------------------------------------\n# 8. Train the RAG-based Model\n# ------------------------------------------\n\n# Load pre-trained model for sequence classification\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n\n# Define training arguments compatible with older Transformers versions\nbatch_size = 16\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=3,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=100,\n    # Set both strategies to \"steps\"\n    eval_strategy=\"steps\",  # Add this line\n    save_strategy=\"steps\",        # Explicitly set this\n    save_steps=100,\n    eval_steps=100,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"f1\",\n    greater_is_better=True\n)\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_val,\n    compute_metrics=compute_metrics\n)\n\n# Train the model\nprint(\"\\nTraining the RAG-based model...\")\ntrainer.train()\n\n# ------------------------------------------\n# 9. Evaluate on Test Set\n# ------------------------------------------\n\nprint(\"\\nEvaluating on test set...\")\ntest_results = trainer.evaluate(tokenized_test)\nprint(f\"Test results: {test_results}\")\n\n# ------------------------------------------\n# 10. Compare with Baseline (No Knowledge)\n# ------------------------------------------\n\nprint(\"\\nPreparing baseline model (without retrieved knowledge)...\")\n\n# Create datasets without retrieved knowledge\ntrain_df['tweet_only'] = train_df['processed_text']\nval_df['tweet_only'] = val_df['processed_text']\ntest_df['tweet_only'] = test_df['processed_text']\n\nbaseline_train = Dataset.from_pandas(train_df[['tweet_only', 'label_encoded']])\nbaseline_val = Dataset.from_pandas(val_df[['tweet_only', 'label_encoded']])\nbaseline_test = Dataset.from_pandas(test_df[['tweet_only', 'label_encoded']])\n\n# Tokenization function for baseline\ndef tokenize_baseline(examples):\n    return tokenizer(\n        examples['tweet_only'],\n        padding=\"max_length\",\n        truncation=True,\n        max_length=max_length\n    )\n\ntokenized_baseline_train = baseline_train.map(tokenize_baseline, batched=True)\ntokenized_baseline_val = baseline_val.map(tokenize_baseline, batched=True)\ntokenized_baseline_test = baseline_test.map(tokenize_baseline, batched=True)\n\n# Train baseline model\nbaseline_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\nbaseline_trainer = Trainer(\n    model=baseline_model,\n    args=training_args,\n    train_dataset=tokenized_baseline_train,\n    eval_dataset=tokenized_baseline_val,\n    compute_metrics=compute_metrics\n)\n\nprint(\"\\nTraining the baseline model...\")\nbaseline_trainer.train()\n\n# Evaluate baseline model\nprint(\"\\nEvaluating baseline model on test set...\")\nbaseline_results = baseline_trainer.evaluate(tokenized_baseline_test)\nprint(f\"Baseline results: {baseline_results}\")\n\n# ------------------------------------------\n# 11. Compare Results\n# ------------------------------------------\n\nprint(\"\\n=== COMPARISON OF RESULTS ===\")\nprint(\"Metric    | Baseline | RAG-based\")\nprint(\"--------------------------------\")\nfor metric in ['accuracy', 'f1', 'precision', 'recall']:\n    baseline_value = baseline_results.get(f'eval_{metric}', 0)\n    rag_value = test_results.get(f'eval_{metric}', 0)\n    diff = rag_value - baseline_value\n    diff_str = f\"{diff:.4f} ({'↑' if diff > 0 else '↓'})\"\n    print(f\"{metric.ljust(10)}| {baseline_value:.4f} | {rag_value:.4f} ({diff_str})\")\n\n# ------------------------------------------\n# 12. Case Study - Qualitative Analysis\n# ------------------------------------------\n\n# Let's examine some examples where RAG and baseline models disagree\nprint(\"\\n=== CASE STUDIES ===\")\n\n# Make predictions using both models\nbaseline_preds = baseline_trainer.predict(tokenized_baseline_test)\nrag_preds = trainer.predict(tokenized_test)\n\nbaseline_labels = baseline_preds.predictions.argmax(-1)\nrag_labels = rag_preds.predictions.argmax(-1)\ntrue_labels = test_df['label_encoded'].values\n\n# Find examples where models disagree\ndisagreement_indices = np.where(baseline_labels != rag_labels)[0]\nprint(f\"Found {len(disagreement_indices)} examples where models disagree\")\n\n# Select a few interesting examples for case study\ncase_study_indices = disagreement_indices[:min(5, len(disagreement_indices))]\nfor idx in case_study_indices:\n    tweet = test_df['processed_text'].iloc[idx]\n    knowledge = test_df['retrieved_knowledge'].iloc[idx]\n    true_label = \"Misinformation\" if true_labels[idx] == 1 else \"Reliable\"\n    baseline_pred = \"Misinformation\" if baseline_labels[idx] == 1 else \"Reliable\"\n    rag_pred = \"Misinformation\" if rag_labels[idx] == 1 else \"Reliable\"\n    \n    print(\"\\n---\")\n    print(f\"Tweet: {tweet}\")\n    print(f\"Retrieved Knowledge: {knowledge}\")\n    print(f\"True Label: {true_label}\")\n    print(f\"Baseline Prediction: {baseline_pred}\")\n    print(f\"RAG Model Prediction: {rag_pred}\")\n    \n    # Highlight which model was correct\n    if rag_labels[idx] == true_labels[idx] and baseline_labels[idx] != true_labels[idx]:\n        print(\"✓ RAG model was correct, baseline was wrong\")\n    elif baseline_labels[idx] == true_labels[idx] and rag_labels[idx] != true_labels[idx]:\n        print(\"✗ Baseline was correct, RAG model was wrong\")\n    else:\n        print(\"Both models were incorrect\")\n\n# ------------------------------------------\n# 13. Save Models and Results\n# ------------------------------------------\n\n# Save the trained RAG model\nprint(\"\\nSaving models...\")\ntrainer.save_model('./rag_model')\nbaseline_trainer.save_model('./baseline_model')\n\n# Save results summary\nresults_summary = {\n    'RAG': test_results,\n    'Baseline': baseline_results,\n    'Sample_Size': len(df_sample)\n}\n\nimport json\nwith open('./results_summary.json', 'w') as f:\n    json.dump(results_summary, f)\n\nprint(\"\\n=== COMPLETED RAG-BASED HEALTH MISINFORMATION DETECTION ===\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-15T05:34:21.410188Z","iopub.execute_input":"2025-04-15T05:34:21.410553Z","execution_failed":"2025-04-15T19:30:41.095Z"}},"outputs":[{"name":"stdout","text":"Using transformers version: 4.51.1\nPyTorch version: 2.5.1+cu124\nCUDA available: False\nLoaded dataset with 12900 entries\n                                             content           label\n0  The CDC currently reports 99031 deaths. In gen...        Reliable\n1  States reported 1121 deaths a small rise from ...        Reliable\n2  Politically Correct Woman (Almost) Uses Pandem...  Misinformation\n3  #IndiaFightsCorona: We have 1524 #COVID testin...        Reliable\n4  Populous states can generate large case counts...        Reliable\n\nClass distribution:\nlabel\nReliable          6719\nMisinformation    6181\nName: count, dtype: int64\n\nTesting retrieval function on sample tweets:\n\nTWEET: the cdc currently reports 99031 deaths. in general the discrepancies in death counts between differe ...\nRETRIEVED: GENERAL INFO: COVID-19 is caused by the SARS-CoV-2 virus and spreads primarily through respiratory d ...\n\nTWEET: states reported 1121 deaths a small rise from last tuesday. southern states reported 640 of those de ...\nRETRIEVED: GENERAL INFO: COVID-19 is caused by the SARS-CoV-2 virus and spreads primarily through respiratory d ...\n\nTWEET: politically correct woman (almost) uses pandemic as excuse not to reuse plastic bag #coronavirus #na ...\nRETRIEVED: GENERAL INFO: COVID-19 is caused by the SARS-CoV-2 virus and spreads primarily through respiratory d ...\n\nTWEET: #indiafightscorona: we have 1524 #covid testing laboratories in india and as on 25th august 2020 368 ...\nRETRIEVED: FACT CHECK: COVID-19 tests are designed to detect current or past infection with the SARS-CoV-2 viru ...\n\nTWEET: populous states can generate large case counts but if you look at the new cases per million today 9  ...\nRETRIEVED: GENERAL INFO: COVID-19 is caused by the SARS-CoV-2 virus and spreads primarily through respiratory d ...\n\nUsing a sample of 1000 tweets to avoid computational overhead\n\nRetrieving external knowledge for tweets...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9300b377aa34969bb1106be49121b6e"}},"metadata":{}},{"name":"stdout","text":"\nExamples of retrieved knowledge:\n\nTWEET: bill gates who is supporting covid-19 vaccine research visited in new zealand during may. ...\nRETRIEVED: FACT CHECK: Claims that Bill Gates is using vaccines for population control are false. ...\nLABEL: Misinformation\n\nTWEET: pak pm imran khan's wife tested positive for covid-19. ...\nRETRIEVED: GENERAL INFO: COVID-19 is caused by the SARS-CoV-2 virus and spreads primarily through respiratory d ...\nLABEL: Misinformation\n\nTWEET: ???clearly, the obama administration did not leave any kind of game plan for something like this.??� ...\nRETRIEVED: GENERAL INFO: COVID-19 is caused by the SARS-CoV-2 virus and spreads primarily through respiratory d ...\nLABEL: Misinformation\n\nTWEET: aaaaaaaaaaaaaaaaaaaaaa it had to hit while i was on spring break ...\nRETRIEVED: GENERAL INFO: COVID-19 is caused by the SARS-CoV-2 virus and spreads primarily through respiratory d ...\nLABEL: Misinformation\n\nTWEET: ukrainian media registered the first confirmed case of the new coronavirus. ...\nRETRIEVED: GENERAL INFO: COVID-19 is caused by the SARS-CoV-2 virus and spreads primarily through respiratory d ...\nLABEL: Misinformation\n\nData split sizes:\nTrain: 700, Validation: 150, Test: 150\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/700 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a98b5c61e242452b927c2350e7aa31c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/150 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f775f8f261794d8181f2d9850f72414a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/150 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48bc08704bd945f185db9f4bf0b9bfc1"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"name":"stdout","text":"\nTraining the RAG-based model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    "},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"!pip install --upgrade transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T05:33:01.102161Z","iopub.execute_input":"2025-04-15T05:33:01.102981Z","iopub.status.idle":"2025-04-15T05:33:15.994076Z","shell.execute_reply.started":"2025-04-15T05:33:01.102953Z","shell.execute_reply":"2025-04-15T05:33:15.992847Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nCollecting transformers\n  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.51.1\n    Uninstalling transformers-4.51.1:\n      Successfully uninstalled transformers-4.51.1\nSuccessfully installed transformers-4.51.3\n","output_type":"stream"}],"execution_count":3}]}